class: center, middle, inverse
## Bayesian Statistics Introduction
@chooblarin

2016/07/14
---

class: inverse

# 3 steps in Parametric model

```
1. パラメータを含むモデルを設定する

2. モデルの評価基準を定める

3. 評価結果が最良となるパラメータをもとめる
```

---
class: inverse
## 評価する基準

- "誤差"を定義して，誤差が最小になるようパラメータを決める
- ある"真となる母数"を持った分布から「データセットが得られる確率」が最大になるようパラメータを決める（最尤推定法）
- それ以外の方法　-> *ベイズ推定*

---
class: inverse
## ベイズ推定の考え方

**真となる母数は確率的に分布する**

最尤推定法では真となるパラメータの値は1つに決まると考えるのに対して，ベイズ推定の場合は分布で扱う（事後分布）．

---
class: inverse
## 条件付き確率と同時確率 (1)

ランダムにボールを1つ出る玩具がある．玩具の中には大きいボールと小さいボールが入っている．ボールの色は赤と白の2種類がある．

![](https://raw.githubusercontent.com/chooblarin/slides/gh-pages/images/bayes/01random-box.png)

1. ボールの色が赤である確率は？
2. ボールが「大きい」とわかっている場合，それが赤である確率は？
3. 出たボールが「大きい赤」である確率は？

---
class: inverse
## 条件付き確率と同時確率 (2)

$$
(1) \;\; P({\rm Red})=\frac{7}{12}
$$

$$
(2) \;\; P({\rm Red}|{\rm Large})=\frac{1}{4}
$$

$$
(3) \;\; P({\rm Red}, {\rm Large})=\frac{1}{12}
$$

(2)は条件付き確率，(3)は同時確率．

$$
P({\rm Red}, {\rm Large})=P({\rm Red}|{\rm Large})P({\rm Large})=P({\rm Large}|{\rm Red})P({\rm Red})
$$

---
class: inverse

## ベイズの定理

条件付き確率の式を変形するとベイズの公式が導ける．

ベイズの公式

$$
P({\rm Y}|{\rm X})=\frac{P({\rm X}|{\rm Y})}{P({\rm X})}P({\rm Y})
$$

or

$$
P({\rm Y}|{\rm X})=\frac{P({\rm X}|{\rm Y})}{\sum_{Y'} P({\rm X}|{\rm Y'})P({\rm Y'})}P({\rm Y})
$$

（周辺確率の公式）

---
class: inverse

## 例題)
ピロリ菌に感染している確率が一般に1%だとする．Aさんは検査を受けてみたら陽性であった．
この検査の精度は95%である．
実際のところ，Aさんが感染している確率は？

---
class: inverse, left

"検査が陽性"という結果を受けて，1%よりもどのくらい確率が上がったのか？

$$
P({\rm 感染}) = 0.01, \; P({\rm 非感染}) = 0.99
$$
$$
P({\rm 陽性}|{\rm 感染}) = 0.95
$$
$$
P({\rm 陰性}|{\rm 感染}) = 0.05
$$
$$
P({\rm 陰性}|{\rm 非感染}) = 0.95
$$
$$
P({\rm 陽性}|{\rm 非感染}) = 0.05
$$

今，知りたいのは
$$
P({\rm 感染}|{\rm 陽性})
$$
の大きさ

---
class: inverse, left

$$
\frac{P({\rm 陽性}|{\rm 感染})}{P({\rm 陽性}|{\rm 感染})P({\rm 感染})+P({\rm 陽性}|{\rm 非感染})P({\rm 非感染})}\; P({\rm 感染})
$$
$$
= \frac{0.95}{0.95 \times 0.01 + 0.05 \times 0.99} \times 0.01 \approx 0.16
$$

検査で陽性が出ても，実際に感染している確率は16%程度だとわかる．（感染している確率が1%しか無かったから．）

前提条件を与えると確率の値は変化する．この性質を利用するのがベイズ推定の基礎．
何も分からない状態から，手掛かりを考慮することで確率がどう変化するのかを考える．

---
class: inverse, left

ベイズの定理 (再掲)
$$
P({\rm Y}|{\rm X})=\frac{P({\rm X}|{\rm Y})}{\sum_{Y'} P({\rm X}|{\rm Y'})P({\rm Y'})}P({\rm Y})
$$

連続確率分布で考えると

$$
P(\mu|{\bf t})=\frac{P({\bf t}|\mu)}{\int_{-\infty}^{\infty}P({\bf t}|\mu ')P(\mu ')d\mu '}P(\mu)
$$

---
class: inverse

## ベイズの定理を成すパーツ

文字で書き下すと

$$
(事後分布)=\frac{(尤度)}{(正規化定数)}(事前分布)
$$

観測データに基づいて，事前分布を事後分布に更新していると捉えて考えられる．

※尤度: 尤もらしさの度合い（観測データのもとで）

※正規化定数: 全確率が1になるという条件を満たすための定数

---
class: inverse
## (余談) ベイズ統計への批判

- 主観的な事前分布を利用することは科学的ではない
- 事前分布は変数変換に対して不変ではない
など（詳しくは後ほど）

---
class: inverse

## ベイズによるパラメータ推定

---
class: inverse

## 信頼区間と信用区間

ベイズ推定では事後分布が得られる．推定結果の報告には **信用区間 (credible interval)** がよく用いられる．
例えば，95%信用区間は「95%の確率で真値がその範囲にある」という意味．

最尤推定法などの結果では信頼区間 (confidence interval) をよく用いるが，この2つは考え方に違いがある．
真値は一つと考えているため，「95%の確率で真値が信頼区間におさまる」という考えは間違いになる．

---
class: center, middle, inverse

# Thanks!

---
class: normal
## References
